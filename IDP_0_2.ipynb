{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Image\n",
    "img = cv.imread(\"testImages/testIMG01.png\")\n",
    "cv.imshow(\"ImG\", img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting to Gray scale\n",
    "gray=cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "cv.imshow(\"Gray\", gray)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we'll convert to binary Image (Black & White) to enhance the chance of text extraction using thresholding.  \n",
    "\n",
    "- We also have to fine-tune the thresh values for better text recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv.threshold(gray, 165, 255, type=cv.THRESH_BINARY_INV)\n",
    "\n",
    "cv.imshow(\"Thresh\", thresh)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To get the size of the words in the images we need a structure element method with kernel size depending up the area of the text.  \n",
    "- We'll use the K-Size of (2,2) or (3, 3).  \n",
    "- (3, 3) is the better one here.  \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect_kernel = cv.getStructuringElement(cv.MORPH_RECT, (2, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll dilate the image to get the boundaries of the text(even if we don't see).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv.dilate(thresh, rect_kernel, iterations = 5)\n",
    "\n",
    "cv.imshow(\"Dilation\", dilation)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we'll find the contours using `findContours` method.  \n",
    "- We'll use the cv.RETR_EXTERNAL for finding the external contours of the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 contours found!\n"
     ]
    }
   ],
   "source": [
    "contours, hierarchy = cv.findContours(dilation, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(f'{len(contours)} contours found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"2nd IMG\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we'll get the coordinates of the white pixel area and draw the bounding box around it.  \n",
    "- We'll also save the text from the image  in the text file.  \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to increase the size and clear the image as a whole.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the size of the img2 by 5-7 times\n",
    "\n",
    "\"\"\" \n",
    "As we'll use Pillow library to resize the image and it recognizes RGB and not BGR.  \n",
    "We'll convert BGR -> RGB\n",
    "\"\"\"\n",
    "\n",
    "# converting BGR -> RGB\n",
    "\n",
    "\n",
    "img2 = cv.cvtColor(img2, cv.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# Converting the image to Pillow image object\n",
    "img2_pil = Image.fromarray(img2)\n",
    "\n",
    "# Getting the length and width of the image\n",
    "length_x, width_y = img2_pil.size\n",
    "\n",
    "\n",
    "# Increasing the size of the image by 5-7 times\n",
    "size = int(5 * length_x), int(5 * width_y)\n",
    "\n",
    "# Re-sizing the cropped image\n",
    "img2_pil_resized = img2_pil.resize(size, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resizing the image using OpenCV only.\n",
    "\n",
    "- We can also resize and scale the images using OpenCV.  \n",
    "- We use `.resize()` function for this.  \n",
    "- Only two inputs arguments are required:\n",
    "    - The source image\n",
    "    - the Desired Size of the resized image, `dsize`.\n",
    "- The various input argument options for `.resize()` are:\n",
    "    `resize(src, dsize, fx, fy, interpolation)`.  \n",
    "    - `src`: the required input image.  \n",
    "    - `dsize`: The desired size of the output image.  it can be a tuple of new height and new width.  \n",
    "    - `fx`: Scale factor along the horizontal axis.  \n",
    "    - `fy`: Scale factor along the vertical axis.  \n",
    "    - `interpolation`: It give us the option of different methods of resizing of an image.  \n",
    "---\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Original\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import INTER_CUBIC, INTER_LINEAR\n",
    "\n",
    "\n",
    "scale_up = 2\n",
    "\n",
    "img_scale_up_linear = cv.resize(img, None, fx=scale_up, fy=scale_up, interpolation= INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import INTER_CUBIC, INTER_LINEAR\n",
    "\n",
    "\n",
    "scale_up = 2\n",
    "\n",
    "img_scale_up_cubic = cv.resize(img, None, fx=scale_up, fy=scale_up, interpolation= INTER_CUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import INTER_CUBIC, INTER_LANCZOS4, INTER_LINEAR\n",
    "\n",
    "\n",
    "scale_up = 2\n",
    "\n",
    "img_scale_up_lanczo = cv.resize(img, None, fx=scale_up, fy=scale_up, interpolation= INTER_LANCZOS4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Scaled Up (LINEAR)\", img_scale_up_linear)\n",
    "cv.imshow(\"Scaled Up (cubic)\", img_scale_up_cubic)\n",
    "cv.imshow(\"Scaled Up (Lanczo)\", img_scale_up_lanczo)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the Noise\n",
    "img_denoise= cv.fastNlMeansDenoisingColored(img_scale_up_lanczo, None, 10, 10,7, 15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray\n",
    "gray_lanczo=cv.cvtColor(img_scale_up_lanczo, cv.COLOR_BGR2GRAY)\n",
    "gray_denoise=cv.cvtColor(img_denoise, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.imshow(\"Scaled Up (LINEAR)\", img_scale_up_linear)\n",
    "# cv.imshow(\"Scaled Up (cubic)\", img_scale_up_cubic)\n",
    "cv.imshow(\"Scaled Up (Lanczo)\", img_scale_up_lanczo)\n",
    "cv.imshow(\"Noise Removed\", img_denoise)\n",
    "\n",
    "# Gray\n",
    "# gray_lanczo=cv.cvtColor(img_scale_up_lanczo, cv.COLOR_BGR2GRAY)\n",
    "# gray_denoise=cv.cvtColor(img_denoise, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "cv.imshow(\"gray_lanczoy\", gray_lanczo)\n",
    "cv.imshow(\"gray_denoise\", gray_denoise)\n",
    "\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_lanczo=cv.cvtColor(img_scale_up_lanczo, cv.COLOR_BGR2GRAY)\n",
    "gray_denoise=cv.cvtColor(img_denoise, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "cv.imshow(\"gray_lanczoy\", gray_lanczo)\n",
    "cv.imshow(\"gray_denoise\", gray_denoise)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "crop_number = 0\n",
    "for cnt in contours:\n",
    "    x,y, w, h = cv.boundingRect(cnt)\n",
    "    \n",
    "    # Draw the bounding box on the text area\n",
    "    rect = cv.rectangle(img2, (x-2, y-2), (x+w, y+h), (0, 255, 2), 1)\n",
    "    \n",
    "    \n",
    "    # Crop the bounding box area\n",
    "    cropped = img2[y-1:y + h, x-1:x+w]\n",
    "\n",
    "    \"\"\" \n",
    "    OpenCv read the color in BGR format, thus we've to convert it to RGB for it to be properly scaling using Pillow.  \n",
    "    We'll convert it to a pillow image object.  \n",
    "    Then we'll resize it using the resize method in the PIL.  \n",
    "    - Convert back to an np array & then back to BGR \n",
    "    \n",
    "    - Now our image is a binary image (Thresholded image) thus we don't have to follow the conversion of BGR to RGB and visa versa. (NO NOT Follow this as we're applying these to img2 and not on img)\n",
    "    \"\"\"\n",
    "    \n",
    "    # converting BGR -> RGB\n",
    "    cropped_RGB = cv.cvtColor(cropped, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Converting image to PIL image object\n",
    "    cropped_pil = Image.fromarray(cropped_RGB)\n",
    "    \n",
    "    # Getting the length and width of the image\n",
    "    length_x, width_y = cropped_pil.size\n",
    "    \n",
    "    \n",
    "    # Increasing the size(length & width) by 5\n",
    "    size = int(7 * length_x), int(7 * width_y)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    length_x, width_y = cropped.shape[:2]\n",
    "    \n",
    "    # length_x = cropped.shape[0]\n",
    "    # width_y = cropped.shape[1]\n",
    "    \n",
    "    size = (5 * int(length_x)), (5 * int(width_y))\n",
    "    \"\"\"\n",
    "    \n",
    "    # Resizing the cropped image\n",
    "    cropped_pil_resized = cropped_pil.resize(size, Image.LANCZOS)\n",
    "    \n",
    "    \n",
    "    # Converting the cropped_pil_resized to cropped_np\n",
    "    cropped_resized = np.array(cropped_pil_resized)\n",
    "    \n",
    "    cropped_resized = cv.cvtColor(cropped_resized, cv.COLOR_RGB2BGR)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Saving the Cropped images as a .jpeg file\n",
    "    cv.imwrite(\"Crop_resized\"+str(crop_number)+\".jpeg\", cropped_resized)\n",
    "    crop_number+=1\n",
    "    \n",
    "    # Open the text file\n",
    "    file = open(\"Text_Output2.txt\", \"a\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # cv.imwrite(\"rectangleBox.jpg\", rect)\n",
    "    \n",
    "    text = pytesseract.image_to_string(cropped_resized)\n",
    "\n",
    "    # Adding the text to the file\n",
    "    file.write(text)\n",
    "    file.write(\"\\n\")\n",
    "    \n",
    "    # Closing the file\n",
    "    file.close()\n",
    "    \n",
    "    # print(text)\n",
    "    \n",
    "cv.imshow(\"BoundBoxed\", rect)\n",
    "cv.imshow(\"Dilation\", dilation)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"BoundBoxed\", rect)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing to improve the quality of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
